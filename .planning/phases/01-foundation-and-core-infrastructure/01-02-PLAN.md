---
phase: 01-foundation-and-core-infrastructure
plan: 02
type: execute
wave: 2
depends_on:
  - "01-01"
files_modified:
  - src/ingot/db/__init__.py
  - src/ingot/db/engine.py
  - src/ingot/db/models.py
  - src/ingot/db/repositories/__init__.py
  - src/ingot/db/repositories/base.py
  - alembic.ini
  - alembic/env.py
  - alembic/script.py.mako
  - alembic/versions/.gitkeep
autonomous: true
requirements:
  - INFRA-07
  - INFRA-08
  - INFRA-09
  - DB-01
  - DB-02
  - DB-03
  - DB-04
  - DB-05
  - DB-06
  - DB-07
  - DB-08
  - DB-09
  - DB-10
  - DB-11

must_haves:
  truths:
    - "All 11 SQLModel table models exist and can be imported without error"
    - "create_async_engine with sqlite+aiosqlite:// creates the database and all tables successfully"
    - "PRAGMA journal_mode returns 'wal' after engine creation — WAL mode is active"
    - "alembic upgrade head runs without error on a fresh database and produces the correct schema"
    - "Concurrent async writes to the same table do not raise SQLITE_BUSY / OperationalError"
    - "Each model can be instantiated, added to a session, committed, and queried back"
  artifacts:
    - path: "src/ingot/db/engine.py"
      provides: "create_async_engine with WAL mode, AsyncSessionLocal factory, get_session() context manager"
      exports: ["engine", "AsyncSessionLocal", "get_session", "init_db"]
    - path: "src/ingot/db/models.py"
      provides: "All 11 SQLModel table models with correct fields and foreign keys"
      exports: ["UserProfile", "Lead", "IntelBrief", "Match", "Email", "FollowUp", "Campaign", "AgentLog", "Venue", "OutreachMetric", "UnsubscribedEmail"]
    - path: "alembic/env.py"
      provides: "Async Alembic migration runner importing SQLModel.metadata"
      contains: "target_metadata = SQLModel.metadata"
    - path: "src/ingot/db/repositories/base.py"
      provides: "BaseRepository with generic add/get/list/update/delete methods"
      exports: ["BaseRepository"]
  key_links:
    - from: "src/ingot/db/engine.py"
      to: "src/ingot/db/models.py"
      via: "SQLModel.metadata.create_all called in init_db()"
      pattern: "SQLModel\\.metadata\\.create_all"
    - from: "alembic/env.py"
      to: "src/ingot/db/models.py"
      via: "from ingot.db.models import * (must import ALL models to register metadata)"
      pattern: "from ingot\\.db\\.models import"
    - from: "src/ingot/db/engine.py"
      to: "WAL PRAGMA"
      via: "@event.listens_for(engine.sync_engine, 'connect') sets PRAGMA journal_mode=WAL"
      pattern: "PRAGMA journal_mode=WAL"
---

<objective>
Build all 11 database models, the async SQLite engine with WAL mode, and Alembic migration — the persistence layer every agent reads and writes.

Purpose: Every agent (Scout, Research, Matcher, Writer) stores its output in SQLite. Without correct async setup and WAL mode, concurrent agent runs cause SQLITE_BUSY errors. Without Alembic, schema evolution is fragile.
Output: `src/ingot/db/` package with engine, all 11 models, repository base class, and working Alembic migration.
</objective>

<execution_context>
@/Users/ishansingh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ishansingh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/phases/01-foundation-and-core-infrastructure/01-RESEARCH.md
@.planning/phases/01-foundation-and-core-infrastructure/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Async SQLite engine with WAL mode and session factory</name>
  <files>
    src/ingot/db/__init__.py
    src/ingot/db/engine.py
  </files>
  <action>
**CRITICAL anti-pattern to avoid:** Do NOT use `from sqlmodel import Session` — that is a sync session and will block the event loop. Always use `AsyncSession` from `sqlmodel.ext.asyncio.session`. Do NOT use URL parameters to set WAL mode — it must be set via PRAGMA in an event listener.

**src/ingot/db/engine.py:**

```python
from pathlib import Path
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy import event, text
from sqlmodel import SQLModel
from ingot.config.manager import ConfigManager

def _get_database_url(base_dir: Path | None = None) -> str:
    if base_dir:
        return f"sqlite+aiosqlite:///{base_dir}/outreach.db"
    cm = ConfigManager()
    return f"sqlite+aiosqlite:///{cm.get_db_path()}"

def create_engine(database_url: str):
    eng = create_async_engine(
        database_url,
        echo=False,
        connect_args={"check_same_thread": False},
    )

    @event.listens_for(eng.sync_engine, "connect")
    def set_sqlite_pragma(dbapi_connection, connection_record):
        cursor = dbapi_connection.cursor()
        cursor.execute("PRAGMA journal_mode=WAL")
        cursor.execute("PRAGMA synchronous=NORMAL")
        cursor.execute("PRAGMA cache_size=-64000")  # 64MB page cache
        cursor.execute("PRAGMA foreign_keys=ON")
        cursor.close()

    return eng

# Module-level engine instance (overridable in tests via dependency injection)
engine = create_engine(_get_database_url())

AsyncSessionLocal = sessionmaker(
    engine, class_=AsyncSession, expire_on_commit=False
)

async def get_session():
    """Async context manager for database sessions."""
    async with AsyncSessionLocal() as session:
        yield session

async def init_db(eng=None):
    """Create all tables. Used for fresh installs and tests."""
    target_engine = eng or engine
    async with target_engine.begin() as conn:
        await conn.run_sync(SQLModel.metadata.create_all)
```

The `init_db()` function imports all models from `ingot.db.models` to ensure they are registered in `SQLModel.metadata` before `create_all` runs. Add `from ingot.db.models import *` at the top of `engine.py`.

**src/ingot/db/__init__.py** — export `engine`, `get_session`, `init_db`, `AsyncSessionLocal`.

Verify WAL after creation by running a quick PRAGMA query:
```python
async with engine.connect() as conn:
    result = await conn.execute(text("PRAGMA journal_mode"))
    assert result.scalar() == "wal"
```
  </action>
  <verify>
    <automated>python -c "
import asyncio, tempfile, pathlib
from ingot.db.engine import create_engine, init_db
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy import text

async def test():
    with tempfile.TemporaryDirectory() as d:
        url = f'sqlite+aiosqlite:///{d}/test.db'
        eng = create_engine(url)
        await init_db(eng)
        # Verify WAL
        async with eng.connect() as conn:
            result = await conn.execute(text('PRAGMA journal_mode'))
            mode = result.scalar()
            assert mode == 'wal', f'WAL not set, got: {mode}'
        await eng.dispose()
    print('WAL OK')

asyncio.run(test())
"
    </automated>
  </verify>
  <done>
    `create_engine()` creates an async engine, `init_db()` creates all tables, and `PRAGMA journal_mode` returns `"wal"`. The `get_session()` context manager yields an `AsyncSession`.
  </done>
</task>

<task type="auto">
  <name>Task 2: All 11 SQLModel table models</name>
  <files>
    src/ingot/db/models.py
    src/ingot/db/repositories/__init__.py
    src/ingot/db/repositories/base.py
  </files>
  <action>
**src/ingot/db/models.py** — all 11 models as SQLModel tables. Use `Optional[X]` for nullable fields, `Field(default_factory=list)` for JSON list fields (stored as JSON strings in SQLite via `sa_column`).

For list fields (skills, experience, education, projects, company_signals, talking_points), use:
```python
from sqlalchemy import Column, JSON
field_name: list[str] = Field(default_factory=list, sa_column=Column(JSON))
```

For enum fields (Lead.status, Campaign.status, FollowUp.status, Email.status), use Python `str` with a validator, NOT a database-level enum (SQLite doesn't have real enums):
```python
class LeadStatus(str, enum.Enum):
    discovered = "discovered"
    researching = "researching"
    matched = "matched"
    drafted = "drafted"
    sent = "sent"
    replied = "replied"
```

**Models to implement (exact field names from REQUIREMENTS.md):**

1. **UserProfile** (DB-01): `id: int | None = Field(default=None, primary_key=True)`, `name: str`, `headline: str = ""`, `skills: list[str]` (JSON), `experience: list[dict]` (JSON), `education: list[dict]` (JSON), `projects: list[dict]` (JSON), `github_url: str = ""`, `linkedin_url: str = ""`, `resume_raw_text: str = ""`, `created_at: datetime = Field(default_factory=datetime.utcnow)`, `updated_at: datetime = Field(default_factory=datetime.utcnow)`

2. **Lead** (DB-02): `id`, `company_name: str`, `person_name: str = ""`, `person_email: str = ""`, `person_role: str = ""`, `company_website: str = ""`, `source_venue: str = ""`, `status: LeadStatus = LeadStatus.discovered`, `initial_score: float = 0.0`, `created_at`

3. **IntelBrief** (DB-03): `id`, `company_name: str`, `company_signals: list[str]` (JSON), `person_name: str = ""`, `person_role: str = ""`, `company_website: str = ""`, `person_background: str = ""`, `talking_points: list[str]` (JSON), `company_product_description: str = ""`, `lead_id: int | None = Field(default=None, foreign_key="lead.id")`, `created_at`

4. **Match** (DB-04): `id`, `match_score: float`, `value_proposition: str`, `confidence_level: str`, `lead_id: int | None = Field(default=None, foreign_key="lead.id")`, `created_at`

5. **Email** (DB-05): `id`, `subject_a: str`, `subject_b: str = ""`, `body: str`, `tone_adapted_for: str = ""`, `mcq_answers_json: str = "{}"`, `status: EmailStatus = EmailStatus.drafted`, `lead_id: int | None = Field(default=None, foreign_key="lead.id")`, `created_at`

6. **FollowUp** (DB-06): `id`, `parent_email_id: int | None = Field(default=None, foreign_key="email.id")`, `scheduled_for_day: int`, `body: str`, `status: FollowUpStatus = FollowUpStatus.queued`, `created_at`, `sent_at: datetime | None = None`

7. **Campaign** (DB-07): `id`, `campaign_name: str`, `created_at`, `started_at: datetime | None = None`, `ended_at: datetime | None = None`, `total_leads: int = 0`, `total_sent: int = 0`, `total_replied: int = 0`, `status: CampaignStatus = CampaignStatus.active`

8. **AgentLog** (DB-08): `id`, `agent_name: str`, `step_description: str`, `status: str`, `duration_ms: int = 0`, `error_message: str = ""`, `input_tokens: int = 0`, `output_tokens: int = 0`, `cost_estimate: float = 0.0`, `created_at`

9. **Venue** (DB-09): `id`, `venue_name: str`, `venue_type: str`, `config_json: str = "{}"`, `last_run_at: datetime | None = None`, `lead_count_discovered: int = 0`, `last_error: str = ""`

10. **OutreachMetric** (DB-10): `id`, `sent_today: int = 0`, `sent_this_hour: int = 0`, `bounce_count: int = 0`, `bounce_rate: float = 0.0`, `last_sent_at: datetime | None = None`, `created_at`

11. **UnsubscribedEmail** (DB-11): `id`, `email_address: str = Field(index=True)`, `unsubscribe_reason: str = ""`, `unsubscribed_at: datetime = Field(default_factory=datetime.utcnow)`

Add `table=True` to every model. All primary keys are `int | None` with `Field(default=None, primary_key=True)`. Import `datetime` from `datetime`, `Optional` from `typing`, `enum` stdlib.

**src/ingot/db/repositories/base.py** — generic `BaseRepository[T]`:
```python
class BaseRepository(Generic[T]):
    def __init__(self, session: AsyncSession, model: type[T]):
        self.session = session
        self.model = model

    async def add(self, obj: T) -> T: ...
    async def get(self, id: int) -> T | None: ...
    async def list(self, limit: int = 100, offset: int = 0) -> list[T]: ...
    async def delete(self, id: int) -> bool: ...
```

Implement using `self.session.add(obj)` + `await self.session.commit()` + `await self.session.refresh(obj)` for add; `await self.session.get(self.model, id)` for get; `select(self.model).limit(limit).offset(offset)` for list.
  </action>
  <verify>
    <automated>python -c "
import asyncio, tempfile
from ingot.db.models import (UserProfile, Lead, IntelBrief, Match, Email,
    FollowUp, Campaign, AgentLog, Venue, OutreachMetric, UnsubscribedEmail)
from ingot.db.engine import create_engine, init_db
from ingot.db.repositories.base import BaseRepository
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import AsyncSession

async def test():
    with tempfile.TemporaryDirectory() as d:
        eng = create_engine(f'sqlite+aiosqlite:///{d}/test.db')
        await init_db(eng)
        Session = sessionmaker(eng, class_=AsyncSession, expire_on_commit=False)
        async with Session() as session:
            lead = Lead(company_name='Acme Corp', person_name='Jane Doe')
            session.add(lead)
            await session.commit()
            await session.refresh(lead)
            assert lead.id is not None
            assert lead.status == 'discovered'

            repo = BaseRepository(session, Lead)
            fetched = await repo.get(lead.id)
            assert fetched.company_name == 'Acme Corp'
        await eng.dispose()
    print('All 11 models OK, BaseRepository OK')

asyncio.run(test())
"
    </automated>
  </verify>
  <done>
    All 11 models import without error. Lead can be created, committed, and retrieved. BaseRepository.get() returns the correct object. All models have the correct field names per REQUIREMENTS.md.
  </done>
</task>

<task type="auto">
  <name>Task 3: Alembic migration setup and initial migration</name>
  <files>
    alembic.ini
    alembic/env.py
    alembic/script.py.mako
    alembic/versions/.gitkeep
  </files>
  <action>
Set up Alembic for async SQLite migrations. Use the async migration pattern from RESEARCH.md Pattern 5.

**alembic.ini:**
```ini
[alembic]
script_location = alembic
sqlalchemy.url = sqlite+aiosqlite:///%(here)s/outreach.db
# The URL here is overridden in env.py for actual use; this is just a fallback

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

**alembic/env.py** — CRITICAL: must import ALL models before `target_metadata = SQLModel.metadata`. This is the #1 Alembic pitfall (Pitfall 3 in RESEARCH.md). Use the async run_migrations_online pattern:

```python
import asyncio
from logging.config import fileConfig
from sqlalchemy import pool
from sqlalchemy.ext.asyncio import create_async_engine
from alembic import context
from sqlmodel import SQLModel

# MUST import all models to register them in SQLModel.metadata
from ingot.db.models import (
    UserProfile, Lead, IntelBrief, Match, Email, FollowUp,
    Campaign, AgentLog, Venue, OutreachMetric, UnsubscribedEmail
)

config = context.config
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = SQLModel.metadata

def get_url():
    from ingot.config.manager import ConfigManager
    cm = ConfigManager()
    return f"sqlite+aiosqlite:///{cm.get_db_path()}"

def run_migrations_offline():
    url = get_url()
    context.configure(
        url=url, target_metadata=target_metadata,
        literal_binds=True, dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()

def do_run_migrations(connection):
    context.configure(connection=connection, target_metadata=target_metadata)
    with context.begin_transaction():
        context.run_migrations()

async def run_migrations_online():
    url = get_url()
    connectable = create_async_engine(url, poolclass=pool.NullPool)
    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)
    await connectable.dispose()

if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_migrations_online())
```

**alembic/script.py.mako** — use the default Alembic template but add `import sqlmodel` to the imports section so generated migration files don't fail:
```mako
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
import sqlmodel
${imports if imports else ""}

revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}

def upgrade() -> None:
    ${upgrades if upgrades else "pass"}

def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
```

**Generate the initial migration:**
```bash
alembic revision --autogenerate -m "initial_schema"
```

This will create `alembic/versions/{hash}_initial_schema.py`. Verify it contains `CREATE TABLE` statements for all 11 models.

**Test the migration on a fresh database:**
```bash
alembic upgrade head
```

If the migration file is empty (Pitfall 3), it means models weren't imported in env.py. Fix the imports and regenerate.
  </action>
  <verify>
    <automated>
# Run migration from scratch in a temp environment
python -c "
import subprocess, tempfile, pathlib, os, asyncio

with tempfile.TemporaryDirectory() as d:
    # Set up a temp DB path
    db_path = pathlib.Path(d) / 'test.db'
    env = {**os.environ, 'INGOT_TEST_DB': str(db_path)}

    # Run alembic upgrade head
    result = subprocess.run(
        ['alembic', 'upgrade', 'head'],
        capture_output=True, text=True, env=env
    )
    if result.returncode != 0:
        print('STDERR:', result.stderr)
        raise AssertionError('alembic upgrade head failed')

    # Verify schema via SQLAlchemy inspection
    from sqlalchemy.ext.asyncio import create_async_engine
    from sqlalchemy import inspect, text

    async def verify():
        eng = create_async_engine(f'sqlite+aiosqlite:///{db_path}')
        async with eng.connect() as conn:
            result = await conn.run_sync(lambda sync_conn: inspect(sync_conn).get_table_names())
            tables = result
            expected = {'userprofile', 'lead', 'intelbrief', 'match', 'email',
                        'followup', 'campaign', 'agentlog', 'venue',
                        'outreachmetric', 'unsubscribedemail'}
            missing = expected - set(t.lower() for t in tables)
            assert not missing, f'Missing tables: {missing}'
        await eng.dispose()
        print('Migration OK, all 11 tables present')

    asyncio.run(verify())
"
    </automated>
  </verify>
  <done>
    `alembic upgrade head` runs without error on a fresh database. All 11 tables are present in the resulting schema. `alembic downgrade base` then `alembic upgrade head` also succeeds.
  </done>
</task>

</tasks>

<verification>
Run after all tasks complete:

```bash
# Verify WAL mode and all models
python -c "
import asyncio, tempfile
from ingot.db.engine import create_engine, init_db
from ingot.db.models import *
from sqlalchemy import text

async def test():
    with tempfile.TemporaryDirectory() as d:
        eng = create_engine(f'sqlite+aiosqlite:///{d}/test.db')
        await init_db(eng)
        async with eng.connect() as conn:
            mode = (await conn.execute(text('PRAGMA journal_mode'))).scalar()
            assert mode == 'wal', f'WAL not enabled: {mode}'
            tables = await conn.run_sync(lambda c: [t for t in c.execute(text(\"SELECT name FROM sqlite_master WHERE type='table'\")).fetchall()])
            print('Tables:', [t[0] for t in tables])
            assert len(tables) == 11, f'Expected 11 tables, got {len(tables)}'
        await eng.dispose()
    print('DB verification OK')

asyncio.run(test())
"

# Concurrent writes test
python -c "
import asyncio, tempfile
from ingot.db.engine import create_engine, init_db
from ingot.db.models import Lead
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import AsyncSession

async def write_lead(Session, name):
    async with Session() as s:
        s.add(Lead(company_name=name))
        await s.commit()

async def test():
    with tempfile.TemporaryDirectory() as d:
        eng = create_engine(f'sqlite+aiosqlite:///{d}/test.db')
        await init_db(eng)
        Session = sessionmaker(eng, class_=AsyncSession, expire_on_commit=False)
        # 10 concurrent writes
        await asyncio.gather(*[write_lead(Session, f'Company {i}') for i in range(10)])
        print('Concurrent writes OK')
        await eng.dispose()

asyncio.run(test())
"
```
</verification>

<success_criteria>
- All 11 SQLModel models import from `ingot.db.models` without error
- WAL mode is confirmed active (`PRAGMA journal_mode` returns `"wal"`) after engine creation
- Alembic `upgrade head` produces all 11 tables on a fresh database
- 10 concurrent async writes to the same table complete without SQLITE_BUSY errors
- `BaseRepository` add/get/list operations work correctly
- All INFRA-07, INFRA-08, INFRA-09 and DB-01 through DB-11 requirements are addressed
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-and-core-infrastructure/01-02-SUMMARY.md` with:
- Exact model field names used (any deviations from REQUIREMENTS.md)
- Alembic migration file location (alembic/versions/{hash}_initial_schema.py)
- WAL verification result
- BaseRepository interface for Plan 01-04 and 01-05 to reference
</output>
