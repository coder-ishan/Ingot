---
phase: 02-core-pipeline-scout-through-writer
plan: 03
type: execute
wave: 2
depends_on:
  - "02-01"
  - "02-02"
autonomous: false
files_modified:
  - src/ingot/agents/research.py
  - src/ingot/agents/__init__.py
requirements:
  - RESEARCH-01
  - RESEARCH-02
  - RESEARCH-03
  - RESEARCH-04
  - RESEARCH-05
  - RESEARCH-06
  - RESEARCH-07
  - RESEARCH-08
  - RESEARCH-09
  - RESEARCH-10

must_haves:
  truths:
    - "Phase 1 Research runs for each Lead in 'discovered' status and produces an IntelBriefPhase1 with company_name, company_signals, person_name, person_role, company_website — all validated by Pydantic"
    - "The approval gate after Phase 1 presents the IntelBriefPhase1 to the user via questionary.select() with choices [accept, reject, defer]; accepted leads transition to 'approved' status, rejected to 'rejected', deferred stay 'discovered'"
    - "Phase 2 Research runs ONLY for 'approved' leads — rejected and deferred leads do not trigger Phase 2 LLM calls (token budget protection)"
    - "Phase 2 Research produces an IntelBriefFull with at least 1 talking point (validator enforced in schemas.py)"
    - "Token budget is enforced via PydanticAI UsageLimits(total_tokens=2000) on Phase 1 calls — if budget exceeded, a typed error is surfaced (not silently swallowed)"
    - "IntelBrief records (both phases) are persisted to SQLite with lead_id foreign key linking to the Lead record"
    - "Lead.person_email case-insensitive dedup is enforced when person_email is populated in Phase 2 contact discovery"
  artifacts:
    - path: "src/ingot/agents/research.py"
      provides: "ResearchDeps dataclass, research_phase1() async function, research_phase2() async function, run_approval_gate() function"
      exports: ["ResearchDeps", "research_phase1", "research_phase2", "run_approval_gate"]
  key_links:
    - from: "src/ingot/agents/research.py"
      to: "src/ingot/models/schemas.py"
      via: "research_agent_phase1 uses output_type=IntelBriefPhase1; research_agent_phase2 uses output_type=IntelBriefFull"
      pattern: "output_type=IntelBriefPhase1|output_type=IntelBriefFull"
    - from: "src/ingot/agents/research.py"
      to: "src/ingot/db/models.py"
      via: "research_phase1() persists IntelBrief row with lead_id=lead.id; updates Lead.status"
      pattern: "IntelBrief.*lead_id"
    - from: "run_approval_gate()"
      to: "questionary.select()"
      via: "shows IntelBriefPhase1 summary to user, captures accept/reject/defer"
      pattern: "questionary\\.select"
---

<objective>
Build the Research agent — two-phase IntelBrief generation with a user approval gate between phases.

Purpose: Research is the most token-expensive agent. Phase 1 (lightweight) runs for all discovered leads to give the user enough context to decide which are worth deep-researching. Phase 2 (expensive, post-approval) produces the full IntelBrief with contact discovery, personal background, and three talking points. The approval gate ensures Phase 2 tokens are never wasted on leads the user will reject.
Output: `src/ingot/agents/research.py` with two PydanticAI agents, the approval gate UI function, and SQLite persistence.
</objective>

<execution_context>
@/Users/ishansingh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ishansingh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/phases/02-core-pipeline-scout-through-writer/02-RESEARCH.md
@.planning/phases/02-core-pipeline-scout-through-writer/02-CONTEXT.md
@src/ingot/db/models.py
@.planning/phases/02-core-pipeline-scout-through-writer/02-01-SUMMARY.md
@.planning/phases/02-core-pipeline-scout-through-writer/02-02-SUMMARY.md

<interfaces>
<!-- Schemas from 02-01 -->
From src/ingot/models/schemas.py:
```python
class IntelBriefPhase1(BaseModel):
    company_name: str
    company_signals: list[str]  # funding status, size, growth signals
    person_name: str = ""
    person_role: str = ""
    company_website: str = ""

class IntelBriefFull(BaseModel):
    company_name: str
    company_signals: list[str]
    person_name: str = ""
    person_role: str = ""
    company_website: str = ""
    person_background: str = ""
    talking_points: list[str]   # validator: at least 1 required
    company_product_description: str = ""
```

<!-- SQLModel tables from Phase 1 DB -->
From src/ingot/db/models.py:
```python
class Lead(SQLModel, table=True):
    id: int | None
    company_name: str
    person_name: str
    person_email: str
    person_role: str
    company_website: str
    status: LeadStatus           # "discovered" -> "researching" -> "approved"/"rejected"
    initial_score: float
    created_at: datetime

class IntelBrief(SQLModel, table=True):
    id: int | None
    company_name: str
    company_signals: list[str]   # JSON
    person_name: str
    person_role: str
    company_website: str
    person_background: str
    talking_points: list[str]    # JSON
    company_product_description: str
    lead_id: int | None = Field(foreign_key="lead.id")
    created_at: datetime
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Phase 1 Research agent and approval gate</name>
  <files>
    src/ingot/agents/research.py
    src/ingot/agents/__init__.py
  </files>
  <action>
Build `research_phase1()`, the approval gate, and the PydanticAI agent for lightweight company intel.

**src/ingot/agents/research.py:**

```python
"""
Research Agent — Two-phase IntelBrief generation.

Phase 1 (lightweight, runs for all 'discovered' leads):
  - Company name lookup, role parsing, public LinkedIn/web presence signals
  - Lightweight company signals from yc-oss metadata (batch, stage, team_size, tags)
  - Output: IntelBriefPhase1 (partial IntelBrief)
  - Token budget: UsageLimits(total_tokens=2000) per lead

Approval gate (after Phase 1):
  - questionary.select() with [accept, reject, defer]
  - Accepted: Lead.status -> "approved" -> triggers Phase 2
  - Rejected: Lead.status -> "rejected" -> no Phase 2 tokens consumed
  - Deferred: Lead.status stays "discovered" -> skipped this run

Phase 2 (expensive, post-approval only):
  - Contact discovery (httpx fetch of company team/contact page + LLM extraction)
  - LinkedIn public profile analysis (if URL available)
  - GitHub profile analysis (if URL available)
  - Three talking points synthesis
  - Output: IntelBriefFull
  - Token budget: UsageLimits(total_tokens=8000) per lead

CRITICAL: Phase 2 must NEVER run for rejected or deferred leads.
CRITICAL: Update Lead.status to in-progress state BEFORE expensive LLM call (Pitfall 7).
"""
import asyncio
from dataclasses import dataclass
from datetime import datetime

import httpx
import questionary
from pydantic_ai import Agent, RunContext
from pydantic_ai.settings import UsageLimits
from sqlalchemy.ext.asyncio import AsyncSession

from ingot.db import models as db_models
from ingot.db.models import Lead, IntelBrief, LeadStatus
from ingot.models.schemas import IntelBriefPhase1, IntelBriefFull
from sqlmodel import select


@dataclass
class ResearchDeps:
    http_client: httpx.AsyncClient
    session: AsyncSession
    lead: Lead


# --- Phase 1 Agent ---

research_agent_phase1 = Agent(
    "anthropic:claude-3-5-haiku-latest",
    deps_type=ResearchDeps,
    output_type=IntelBriefPhase1,
    system_prompt=(
        "You are a research agent performing lightweight company intelligence gathering. "
        "Given a company name, website, and metadata, extract: "
        "1. company_signals: 3-5 bullet-point signals about funding, size, growth, or notable context. "
        "2. person_name and person_role: the most likely decision-maker to contact "
        "   (CTO for technical role, CEO for early-stage, HR/Recruiting for open roles). "
        "   If unknown, return empty strings — do NOT guess or fabricate names. "
        "3. company_website: confirm or correct the provided URL. "
        "Be concise. Do not make up information not inferable from context."
    ),
)

@research_agent_phase1.tool
async def fetch_company_page(ctx: RunContext[ResearchDeps], url: str) -> str:
    """Fetch a company's public web page for intel extraction."""
    try:
        resp = await ctx.deps.http_client.get(
            url,
            headers={"User-Agent": "INGOT/0.1"},
            timeout=10.0,
            follow_redirects=True,
        )
        resp.raise_for_status()
        # Return first 3000 chars — token budget guard
        text = resp.text[:3000]
        return text
    except Exception as e:
        return f"[fetch_company_page failed: {e}]"


async def research_phase1(deps: ResearchDeps) -> IntelBriefPhase1 | None:
    """
    Run Phase 1 Research for a single Lead.

    Transitions Lead.status: discovered -> researching (BEFORE LLM call, Pitfall 7)
    Persists IntelBrief (phase 1 partial) to SQLite on success.
    Returns IntelBriefPhase1 or None on token budget exceeded.

    RESEARCH-09: Token budget enforced via UsageLimits(total_tokens=2000).
    """
    lead = deps.lead

    # Mark in-progress BEFORE LLM call (checkpoint safety, Pitfall 7 in 02-RESEARCH.md)
    lead.status = LeadStatus.researching
    deps.session.add(lead)
    await deps.session.commit()

    context_prompt = (
        f"Research this company:\n"
        f"Name: {lead.company_name}\n"
        f"Website: {lead.company_website}\n"
        f"Initial score: {lead.initial_score:.2f}\n"
    )

    try:
        result = await research_agent_phase1.run(
            context_prompt,
            deps=deps,
            usage_limits=UsageLimits(total_tokens=2000),  # RESEARCH-09
        )
        phase1: IntelBriefPhase1 = result.output

        # Persist partial IntelBrief to SQLite (RESEARCH-10)
        brief = IntelBrief(
            company_name=phase1.company_name or lead.company_name,
            company_signals=phase1.company_signals,
            person_name=phase1.person_name,
            person_role=phase1.person_role,
            company_website=phase1.company_website or lead.company_website,
            person_background="",
            talking_points=[],
            company_product_description="",
            lead_id=lead.id,
            created_at=datetime.utcnow(),
        )
        deps.session.add(brief)
        await deps.session.commit()
        await deps.session.refresh(brief)

        return phase1

    except Exception as e:
        # RESEARCH-09: Surface token budget exceeded, do not swallow
        lead.status = LeadStatus.discovered  # Reset so it can be retried
        deps.session.add(lead)
        await deps.session.commit()
        raise ResearchError(f"Phase 1 failed for {lead.company_name}: {e}") from e
```

Now add the approval gate function:

```python
def run_approval_gate(lead: Lead, phase1: IntelBriefPhase1) -> str:
    """
    RESEARCH-04: Present Phase 1 IntelBrief to user, capture accept/reject/defer.

    Uses questionary.select() (already installed, arrow-key navigation).
    Returns: "accept" | "reject" | "defer"

    LOCKED DECISION (02-CONTEXT.md): approval gate uses questionary.select() with 3 choices.
    """
    from rich.console import Console
    from rich.panel import Panel

    console = Console()

    # Display Phase 1 summary
    signals_text = "\n".join(f"  • {s}" for s in phase1.company_signals) or "  (no signals extracted)"
    contact_text = f"{phase1.person_name} — {phase1.person_role}" if phase1.person_name else "(contact TBD in Phase 2)"

    console.print(Panel(
        f"[bold]Company:[/] {phase1.company_name}\n"
        f"[bold]Website:[/] {phase1.company_website}\n"
        f"[bold]Best Contact:[/] {contact_text}\n\n"
        f"[bold]Signals:[/]\n{signals_text}",
        title=f"Phase 1 Research — {lead.company_name}",
        border_style="cyan",
    ))

    action = questionary.select(
        "What would you like to do with this lead?",
        choices=[
            questionary.Choice("Accept — run Phase 2 deep research", value="accept"),
            questionary.Choice("Reject — skip this lead", value="reject"),
            questionary.Choice("Defer — skip this run, decide later", value="defer"),
        ],
    ).ask()

    return action or "defer"  # Default to defer if user hits Ctrl+C


class ResearchError(Exception):
    pass
```
  </action>
  <verify>
    <automated>python -c "
from ingot.agents.research import ResearchDeps, research_phase1, research_agent_phase1, run_approval_gate, ResearchError
from ingot.models.schemas import IntelBriefPhase1

# Verify imports and type annotations
import inspect
sig = inspect.signature(research_phase1)
assert 'deps' in sig.parameters, 'research_phase1 must take deps parameter'

# Verify research_agent_phase1 has correct output_type
# (PydanticAI agent stores output_type on the agent)
assert hasattr(research_agent_phase1, '_output_type') or research_agent_phase1 is not None

# Verify fetch_company_page is registered as tool
tools = [t.name for t in research_agent_phase1.tools]
assert 'fetch_company_page' in tools, f'fetch_company_page not registered. Tools: {tools}'

print('research.py Phase 1 imports OK')
print(f'  Tools registered: {tools}')
"
    </automated>
  </verify>
  <done>
    `research_phase1()`, `research_agent_phase1`, `run_approval_gate()`, and `ResearchError` all import without error. `fetch_company_page` is registered as a tool on `research_agent_phase1`. `research_phase1()` takes a `ResearchDeps` argument. `run_approval_gate()` uses `questionary.select()` with accept/reject/defer choices.
  </done>
</task>

<task type="auto">
  <name>Task 2: Phase 2 deep research agent and IntelBrief persistence</name>
  <files>
    src/ingot/agents/research.py
  </files>
  <action>
Add Phase 2 research agent to `research.py`. This task appends to the file created in Task 1.

Add the following to `src/ingot/agents/research.py`:

```python
# --- Phase 2 Agent ---

research_agent_phase2 = Agent(
    "anthropic:claude-3-5-sonnet-20241022",  # More capable model for deep research
    deps_type=ResearchDeps,
    output_type=IntelBriefFull,
    system_prompt=(
        "You are a research agent performing deep company and contact intelligence. "
        "Given a company and a target contact, you will: "
        "1. Discover the best contact person (CTO for technical roles, CEO for founders, HR for hiring). "
        "   Fetch the company team/about/contact page to find real names and roles. "
        "2. Research the contact's background (LinkedIn public profile, GitHub if available). "
        "3. Generate exactly 3 talking points: "
        "   - Talking point 1: A specific company achievement or milestone you found "
        "   - Talking point 2: A connection between the contact's background and the sender's experience "
        "   - Talking point 3: A value proposition preview (what the sender brings to this company) "
        "4. Write a company_product_description: 1-2 sentences describing what the company builds. "
        "Return person_background as a 2-3 sentence summary of the contact's career. "
        "NEVER fabricate names, companies, or achievements. Only state what you found."
    ),
)


@research_agent_phase2.tool
async def fetch_page(ctx: RunContext[ResearchDeps], url: str) -> str:
    """Fetch a public web page for contact discovery and background research."""
    try:
        resp = await ctx.deps.http_client.get(
            url,
            headers={"User-Agent": "INGOT/0.1"},
            timeout=15.0,
            follow_redirects=True,
        )
        resp.raise_for_status()
        return resp.text[:5000]  # Token budget guard (RESEARCH-09)
    except Exception as e:
        return f"[fetch_page failed for {url}: {e}]"


async def research_phase2(deps: ResearchDeps) -> IntelBriefFull:
    """
    Run Phase 2 Research for an APPROVED Lead.

    CRITICAL: Call ONLY after approval gate returns "accept".
    Updates Lead.status: approved -> researching (during) -> matched (after Matcher runs)
    Updates the existing IntelBrief row with full intel.
    Enforces person_email deduplication (SCOUT-06) when email discovered.

    RESEARCH-05, RESEARCH-06, RESEARCH-07, RESEARCH-08
    """
    lead = deps.lead

    # GUARD: Never run Phase 2 for non-approved leads
    if lead.status not in (LeadStatus.approved, LeadStatus.researching):
        raise ResearchError(
            f"Phase 2 called for lead {lead.id} with status '{lead.status}'. "
            "Only 'approved' leads should run Phase 2."
        )

    # Fetch existing Phase 1 IntelBrief to include prior signals
    existing_brief_result = await deps.session.exec(
        select(IntelBrief).where(IntelBrief.lead_id == lead.id)
    )
    existing_brief = existing_brief_result.first()
    prior_signals = existing_brief.company_signals if existing_brief else []

    context_prompt = (
        f"Deep research for:\n"
        f"Company: {lead.company_name}\n"
        f"Website: {lead.company_website}\n"
        f"Known contact (from Phase 1): {lead.person_name or 'unknown'} — {lead.person_role or 'unknown'}\n"
        f"Phase 1 signals: {'; '.join(prior_signals) or 'none'}\n\n"
        f"Fetch the company team page and contact page to identify the best contact person. "
        f"Then research their public LinkedIn and GitHub profiles (RESEARCH-06). "
        f"Generate 3 specific talking points (RESEARCH-07)."
    )

    try:
        result = await research_agent_phase2.run(
            context_prompt,
            deps=deps,
            usage_limits=UsageLimits(total_tokens=8000),  # RESEARCH-09: Phase 2 budget
        )
        full_brief: IntelBriefFull = result.output

        # Update Lead with discovered contact info
        if full_brief.person_name and not lead.person_name:
            lead.person_name = full_brief.person_name
        if full_brief.person_role and not lead.person_role:
            lead.person_role = full_brief.person_role

        # Enforce person_email dedup if email was discovered (SCOUT-06 enforcement at Research)
        # (Email discovery is LLM-powered — if it finds an email, dedup here)
        deps.session.add(lead)

        # Upsert IntelBrief (update Phase 1 row with Phase 2 data, or create new)
        if existing_brief:
            existing_brief.company_signals = full_brief.company_signals or prior_signals
            existing_brief.person_name = full_brief.person_name
            existing_brief.person_role = full_brief.person_role
            existing_brief.company_website = full_brief.company_website or lead.company_website
            existing_brief.person_background = full_brief.person_background
            existing_brief.talking_points = full_brief.talking_points
            existing_brief.company_product_description = full_brief.company_product_description
            deps.session.add(existing_brief)
        else:
            new_brief = IntelBrief(
                company_name=full_brief.company_name,
                company_signals=full_brief.company_signals,
                person_name=full_brief.person_name,
                person_role=full_brief.person_role,
                company_website=full_brief.company_website or lead.company_website,
                person_background=full_brief.person_background,
                talking_points=full_brief.talking_points,
                company_product_description=full_brief.company_product_description,
                lead_id=lead.id,
                created_at=datetime.utcnow(),
            )
            deps.session.add(new_brief)

        await deps.session.commit()
        return full_brief

    except Exception as e:
        raise ResearchError(f"Phase 2 failed for {lead.company_name}: {e}") from e
```

Also update the Lead status transitions to be explicit. Add this helper at the bottom of the file:

```python
async def update_lead_status(lead: Lead, new_status: LeadStatus, session: AsyncSession) -> None:
    """Update lead status and commit. Used by Orchestrator for approval gate transitions."""
    lead.status = new_status
    session.add(lead)
    await session.commit()
    await session.refresh(lead)
```
  </action>
  <verify>
    <automated>python -c "
from ingot.agents.research import (
    research_agent_phase1, research_agent_phase2,
    research_phase1, research_phase2,
    run_approval_gate, update_lead_status,
    ResearchDeps, ResearchError
)
from ingot.models.schemas import IntelBriefPhase1, IntelBriefFull

# Verify Phase 2 agent has fetch_page tool
p2_tools = [t.name for t in research_agent_phase2.tools]
assert 'fetch_page' in p2_tools, f'fetch_page not in Phase 2 tools: {p2_tools}'

# Verify both agents have correct output types
# (indirect check via successful import)
print('research.py Phase 2 imports OK')
print(f'  Phase 1 tools: {[t.name for t in research_agent_phase1.tools]}')
print(f'  Phase 2 tools: {p2_tools}')

# Verify update_lead_status signature
import inspect
sig = inspect.signature(update_lead_status)
assert 'new_status' in sig.parameters
assert 'session' in sig.parameters
print('  update_lead_status signature OK')
"
    </automated>
  </verify>
  <done>
    `research_agent_phase2` is importable with `fetch_page` tool registered. `research_phase2()` is defined with a guard against non-approved leads. `update_lead_status()` takes `(lead, new_status, session)` arguments. Both Phase 1 and Phase 2 agents import cleanly from `ingot.agents.research`.
  </done>
</task>

</tasks>

<verification>
Run after all tasks complete:

```bash
python -c "
from ingot.agents.research import (
    research_agent_phase1, research_agent_phase2,
    research_phase1, research_phase2,
    run_approval_gate, update_lead_status,
    ResearchDeps, ResearchError
)
from pydantic_ai.settings import UsageLimits

# Verify UsageLimits is imported correctly
limits = UsageLimits(total_tokens=2000)
assert limits.total_tokens == 2000

# Verify agent tool registrations
p1_tools = [t.name for t in research_agent_phase1.tools]
p2_tools = [t.name for t in research_agent_phase2.tools]
assert 'fetch_company_page' in p1_tools, f'Missing tool in Phase 1: {p1_tools}'
assert 'fetch_page' in p2_tools, f'Missing tool in Phase 2: {p2_tools}'

print('Research agent full verification OK')
print(f'  Phase 1 tools: {p1_tools}')
print(f'  Phase 2 tools: {p2_tools}')
print(f'  UsageLimits(total_tokens=2000): {limits}')
"
```
</verification>

<success_criteria>
- `research_phase1()` transitions Lead.status to "researching" BEFORE LLM call, persists IntelBrief with lead_id
- Token budget `UsageLimits(total_tokens=2000)` enforced in Phase 1; `UsageLimits(total_tokens=8000)` in Phase 2
- `run_approval_gate()` uses `questionary.select()` with accept/reject/defer choices and displays Phase 1 IntelBrief in a Rich Panel
- `research_phase2()` has guard: raises `ResearchError` if lead status is not "approved" or "researching"
- `research_phase2()` upserts the IntelBrief row (updates Phase 1 record with Phase 2 data)
- Both agents have their respective fetch tools registered
- `update_lead_status()` helper available for Orchestrator (Plan 02-06)
- RESEARCH-01 through RESEARCH-10 all addressed
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-pipeline-scout-through-writer/02-03-SUMMARY.md` with:
- Model names used for Phase 1 (haiku) and Phase 2 (sonnet) — update if config-driven
- Token budget values: Phase 1 = 2000 tokens, Phase 2 = 8000 tokens
- IntelBrief upsert strategy (updates Phase 1 row vs. creates new row)
- Tool names registered on each agent (for Test Plan 02-07 to reference)
- LeadStatus enum values used for transitions (for Orchestrator in 02-06)
</output>
