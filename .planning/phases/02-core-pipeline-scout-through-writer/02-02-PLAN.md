---
phase: 02-core-pipeline-scout-through-writer
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/ingot/venues/yc.py
  - src/ingot/venues/__init__.py
  - src/ingot/scoring/scorer.py
  - src/ingot/scoring/__init__.py
  - src/ingot/agents/scout.py
  - src/ingot/agents/__init__.py
autonomous: true
requirements:
  - SCOUT-01
  - SCOUT-02
  - SCOUT-03
  - SCOUT-04
  - SCOUT-05
  - SCOUT-06
  - SCOUT-07
  - SCOUT-08

must_haves:
  truths:
    - "fetch_yc_companies() fetches from yc-oss.github.io/api/ (NOT ycombinator.com) and returns a list of company dicts with at least 100 entries"
    - "score_lead() produces a float 0.0-1.0 using the documented 4-factor weighted formula (stack_domain_match=0.40, company_stage=0.25, job_keyword_match=0.20, semantic_similarity=0.15); ScoringWeights is a visible dataclass the user can tune"
    - "Lead deduplication is case-insensitive on person_email: inserting the same email twice results in exactly one Lead row in SQLite"
    - "scout_run() returns a list of Lead db records sorted by initial_score descending, limited to 10-20 leads, all with status='discovered'"
    - "Output validation rejects any lead where more than 20% of required fields (company_name, company_website, person_email) are None"
    - "User-agent header 'INGOT/0.1' is set on all httpx requests to yc-oss API"
  artifacts:
    - path: "src/ingot/venues/yc.py"
      provides: "fetch_yc_companies(http_client, batch=None) async function, YC_OSS_BASE_URL constant, company record field documentation"
      exports: ["fetch_yc_companies", "YC_OSS_BASE_URL"]
    - path: "src/ingot/scoring/scorer.py"
      provides: "ScoringWeights dataclass with documented weights, score_lead() function using TF-IDF cosine similarity"
      exports: ["ScoringWeights", "score_lead", "DEFAULT_WEIGHTS"]
    - path: "src/ingot/agents/scout.py"
      provides: "ScoutDeps dataclass, scout_run() async function returning list[db Lead]"
      exports: ["scout_run", "ScoutDeps"]
  key_links:
    - from: "src/ingot/agents/scout.py"
      to: "src/ingot/venues/yc.py"
      via: "scout_run() calls fetch_yc_companies(ctx.deps.http_client)"
      pattern: "fetch_yc_companies"
    - from: "src/ingot/agents/scout.py"
      to: "src/ingot/scoring/scorer.py"
      via: "scout_run() calls score_lead(company, user_skills, weights)"
      pattern: "score_lead"
    - from: "src/ingot/agents/scout.py"
      to: "src/ingot/db/models.py"
      via: "Dedup check via session.exec(select(Lead).where(Lead.person_email.ilike(email)))"
      pattern: "ilike.*person_email"
---

<objective>
Build the Scout agent — YC lead discovery via the yc-oss JSON API, documented weighted scoring, and deduplication.

Purpose: Scout is the pipeline entry point. It discovers leads from YC, scores them for relevance against the user's resume skills, deduplicates against existing SQLite records, and persists 10-20 qualified leads with status "discovered" for the Research agent to process.
Output: `src/ingot/venues/yc.py` (data fetch), `src/ingot/scoring/scorer.py` (scoring formula), `src/ingot/agents/scout.py` (agent orchestration).
</objective>

<execution_context>
@/Users/ishansingh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ishansingh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/phases/02-core-pipeline-scout-through-writer/02-RESEARCH.md
@.planning/phases/02-core-pipeline-scout-through-writer/02-CONTEXT.md
@src/ingot/db/models.py

<interfaces>
<!-- SQLModel Lead table — dedup and persistence target -->
From src/ingot/db/models.py:
```python
class Lead(SQLModel, table=True):
    id: int | None = Field(default=None, primary_key=True)
    company_name: str
    person_name: str = ""
    person_email: str = ""
    person_role: str = ""
    company_website: str = ""
    source_venue: str = ""
    status: LeadStatus = LeadStatus.discovered   # "discovered" on creation
    initial_score: float = 0.0
    created_at: datetime

# AsyncSession from src/ingot/db/engine.py
async def get_session() -> AsyncGenerator[AsyncSession, None]: ...
```

<!-- yc-oss company record fields (verified 2026-02-26) -->
YC-OSS JSON record example:
```json
{
  "id": 123, "name": "Stripe", "slug": "stripe",
  "website": "https://stripe.com",
  "one_liner": "Economic infrastructure for the internet",
  "long_description": "Stripe builds financial infrastructure...",
  "team_size": 8000, "industry": "Fintech", "subindustry": "Payments",
  "tags": ["B2B", "SaaS", "Developer Tools"],
  "batch": "S09", "stage": "Series B", "status": "Active",
  "isHiring": true
}
```
NOTE: `tags` contains domain/category tags (B2B, SaaS) NOT technology names.
Tech stack signals are in `one_liner` and `long_description` free text.
</interfaces>

<scoring_formula>
## Scoring Formula (from 02-CONTEXT.md — LOCKED DECISIONS)

4-factor weighted formula. Weights are VISIBLE and TUNABLE via ScoringWeights dataclass.

| Factor | Weight | Signal Source | Implementation |
|--------|--------|---------------|----------------|
| stack_domain_match | 0.40 | tech terms in one_liner + long_description vs. user skills | keyword intersection + tag domain match |
| company_stage | 0.25 | stage field ("seed", "series a" preferred) | stage preference lookup |
| job_keyword_match | 0.20 | one_liner keyword overlap with user skills | term frequency match |
| semantic_similarity | 0.15 | TF-IDF cosine(long_description, resume_raw_text) | sklearn TfidfVectorizer |

PITFALL: Do NOT use yc-oss `tags` for stack_domain_match — tags are domain categories (B2B, SaaS),
not technologies. Extract tech terms from `one_liner` + `long_description` free text.
</scoring_formula>
</context>

<tasks>

<task type="auto">
  <name>Task 1: YC-OSS data fetcher and weighted scoring formula</name>
  <files>
    src/ingot/venues/__init__.py
    src/ingot/venues/yc.py
    src/ingot/scoring/__init__.py
    src/ingot/scoring/scorer.py
  </files>
  <action>
**src/ingot/venues/yc.py** — YC-OSS JSON API fetcher:

```python
"""
YC Company data fetcher using the yc-oss community JSON API.

PRIMARY SOURCE: https://yc-oss.github.io/api/
- Refreshed daily via GitHub Actions from YC's Algolia index
- 5,690+ publicly launched companies in clean JSON
- NO scraping, NO JavaScript rendering, NO Playwright needed

DO NOT scrape ycombinator.com directly:
- Their company directory uses Algolia + infinite scroll JS rendering
- httpx GET returns <div id="__next"> with no company data (Pitfall 1 in 02-RESEARCH.md)
"""
import asyncio
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential

YC_OSS_BASE_URL = "https://yc-oss.github.io/api"
YC_HEADERS = {"User-Agent": "INGOT/0.1 (outreach tool; github.com/ingot-app/ingot)"}


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10))
async def fetch_yc_companies(
    http_client: httpx.AsyncClient,
    batch: str | None = None,
    industry: str | None = None,
) -> list[dict]:
    """
    Fetch YC company records from yc-oss GitHub Pages API.

    Args:
        http_client: Shared async httpx client (from ScoutDeps)
        batch: YC batch slug e.g. "winter-2025", "summer-2024". None = all companies.
        industry: Industry slug e.g. "b2b", "consumer". None = all industries.

    Returns:
        List of company dicts. Each has: id, name, slug, website, one_liner,
        long_description, team_size, industry, tags, batch, stage, isHiring.

    Raises:
        httpx.HTTPError on network failure (tenacity retries 3 times).
    """
    if batch:
        url = f"{YC_OSS_BASE_URL}/batches/{batch}.json"
    elif industry:
        url = f"{YC_OSS_BASE_URL}/industries/{industry}.json"
    else:
        url = f"{YC_OSS_BASE_URL}/companies/all.json"

    try:
        resp = await http_client.get(url, headers=YC_HEADERS, timeout=30.0)
        resp.raise_for_status()
        companies = resp.json()
    except httpx.HTTPStatusError:
        if batch or industry:
            # Batch/industry not found — fall back to all companies
            resp = await http_client.get(
                f"{YC_OSS_BASE_URL}/companies/all.json",
                headers=YC_HEADERS,
                timeout=30.0
            )
            resp.raise_for_status()
            companies = resp.json()
        else:
            raise

    assert isinstance(companies, list), f"Expected list, got {type(companies)}"
    assert len(companies) > 100, f"Suspiciously few companies: {len(companies)}"
    return companies
```

**src/ingot/scoring/scorer.py** — documented weighted formula:

```python
"""
Lead scoring formula for INGOT Scout agent.

WEIGHTS ARE INTENTIONALLY VISIBLE AND TUNABLE.
Edit ScoringWeights or pass a custom instance to score_lead().
Decision rationale documented in .planning/phases/02-core-pipeline-scout-through-writer/02-CONTEXT.md.

Scoring formula (from 02-CONTEXT.md locked decisions):
  - stack_domain_match: ~40% — primary signal; tech terms in description vs. user skills
  - company_stage:       ~25% — seed/Series A preferred for outsized early-hire impact
  - job_keyword_match:   ~20% — intent signal when isHiring=True + skill keywords present
  - semantic_similarity: ~15% — TF-IDF cosine(long_description, resume_text) catches gaps

PITFALL: yc-oss `tags` field contains category tags (B2B, SaaS, Developer Tools),
NOT technology names. Use one_liner + long_description free text for stack_domain_match.
"""
from dataclasses import dataclass
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re


@dataclass
class ScoringWeights:
    """
    Weighted lead scoring formula.
    Sum must equal 1.0. Edit here or pass custom instance to score_lead().

    Tune by modifying these values. Document your change rationale in comments.
    """
    stack_domain_match: float = 0.40
    company_stage: float = 0.25
    job_keyword_match: float = 0.20
    semantic_similarity: float = 0.15

    def __post_init__(self):
        total = self.stack_domain_match + self.company_stage + self.job_keyword_match + self.semantic_similarity
        assert abs(total - 1.0) < 0.001, f"ScoringWeights must sum to 1.0, got {total}"


DEFAULT_WEIGHTS = ScoringWeights()

# Stage preference scores (seed/Series A = high impact potential)
_STAGE_SCORES: dict[str, float] = {
    "seed": 1.0,
    "series a": 1.0,
    "pre-seed": 0.9,
    "series b": 0.7,
    "series c": 0.5,
    "series d": 0.4,
    "series e": 0.3,
    "public": 0.2,
    "acquired": 0.1,
}


def _extract_tech_terms(text: str) -> set[str]:
    """
    Extract technology-like terms from free text.
    Matches: capitalized acronyms (API, SDK), CamelCase (TypeScript), version strings (Python3),
    and common technology terms. NOT soft skills.
    """
    # Match tech-like tokens: 2+ char sequences, camelCase, all-caps acronyms, versioned terms
    tokens = re.findall(r'\b[A-Z][a-zA-Z0-9]+\b|\b[A-Z]{2,}\b|\b[a-z]+\d+\b', text)
    return {t.lower() for t in tokens if len(t) >= 2}


def _stack_domain_score(company: dict, user_skills: list[str]) -> float:
    """
    Score based on tech term overlap between company description and user skills.
    Checks one_liner + long_description text (NOT tags — those are domain categories).
    """
    company_text = f"{company.get('one_liner', '')} {company.get('long_description', '')}"
    company_terms = _extract_tech_terms(company_text)

    # Also include tag-based domain match (developer tools, infrastructure = +boost)
    high_value_tags = {"developer tools", "infrastructure", "devtools", "dev tools", "b2b"}
    tag_bonus = 0.1 if any(t.lower() in high_value_tags for t in company.get("tags", [])) else 0.0

    if not user_skills or not company_terms:
        return tag_bonus

    skill_terms = {s.lower() for s in user_skills}
    overlap = len(company_terms & skill_terms)
    union = len(company_terms | skill_terms)
    jaccard = overlap / union if union > 0 else 0.0
    return min(1.0, jaccard * 3.0 + tag_bonus)  # scale up; jaccard is typically small


def _stage_score(company: dict) -> float:
    """Score based on company funding stage. Seed/Series A preferred."""
    stage = company.get("stage", "").lower().strip()
    # Try exact match first, then substring match
    if stage in _STAGE_SCORES:
        return _STAGE_SCORES[stage]
    for key, val in _STAGE_SCORES.items():
        if key in stage:
            return val
    # Default: batch-based estimation (older = more mature = lower impact potential)
    batch = company.get("batch", "")
    if batch:
        try:
            year = int(batch[-2:]) + 2000
            if year >= 2023:
                return 0.7  # Recent batch = likely early stage
            elif year >= 2020:
                return 0.5
            else:
                return 0.3
        except (ValueError, IndexError):
            pass
    return 0.3


def _job_keyword_score(company: dict, user_skills: list[str]) -> float:
    """
    Score based on hiring signal + keyword match.
    isHiring=True with overlapping skills in one_liner = strong intent signal.
    """
    is_hiring = company.get("isHiring", False)
    one_liner = company.get("one_liner", "").lower()
    skill_hits = sum(1 for s in user_skills if s.lower() in one_liner)

    base = 0.5 if is_hiring else 0.0
    skill_boost = min(0.5, skill_hits * 0.15)
    return min(1.0, base + skill_boost)


def _semantic_score(company: dict, resume_text: str) -> float:
    """
    TF-IDF cosine similarity between company long_description and user resume.
    Catches semantic overlap missed by keyword matching.
    Returns 0.0 if either text is empty.
    """
    company_desc = company.get("long_description", "") or company.get("one_liner", "")
    if not company_desc or not resume_text:
        return 0.0
    try:
        vectorizer = TfidfVectorizer(stop_words="english", max_features=500)
        tfidf_matrix = vectorizer.fit_transform([company_desc, resume_text])
        score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        return float(min(1.0, score))
    except Exception:
        return 0.0


def score_lead(
    company: dict,
    user_skills: list[str],
    resume_text: str = "",
    weights: ScoringWeights = DEFAULT_WEIGHTS,
) -> float:
    """
    Score a YC company against user skills. Returns float 0.0-1.0.

    Weights are documented in ScoringWeights docstring.
    To tune: pass a custom ScoringWeights instance.
    """
    stack = _stack_domain_score(company, user_skills)
    stage = _stage_score(company)
    keyword = _job_keyword_score(company, user_skills)
    semantic = _semantic_score(company, resume_text)

    return (
        weights.stack_domain_match * stack
        + weights.company_stage * stage
        + weights.job_keyword_match * keyword
        + weights.semantic_similarity * semantic
    )
```

Create `src/ingot/venues/__init__.py` and `src/ingot/scoring/__init__.py` as empty package files.
  </action>
  <verify>
    <automated>python -c "
from ingot.venues.yc import fetch_yc_companies, YC_OSS_BASE_URL
from ingot.scoring.scorer import ScoringWeights, score_lead, DEFAULT_WEIGHTS

# Test ScoringWeights validation
weights = ScoringWeights()
total = weights.stack_domain_match + weights.company_stage + weights.job_keyword_match + weights.semantic_similarity
assert abs(total - 1.0) < 0.001, f'Weights do not sum to 1.0: {total}'

# Test scoring with a realistic company
company = {
    'name': 'DevTools Inc',
    'one_liner': 'Python SDK for API developers',
    'long_description': 'We build Python and TypeScript tooling for REST API development',
    'stage': 'Seed',
    'isHiring': True,
    'tags': ['Developer Tools', 'B2B'],
    'batch': 'W24',
}
user_skills = ['Python', 'TypeScript', 'REST APIs', 'React']
score = score_lead(company, user_skills, resume_text='Python TypeScript API development')
assert 0.0 <= score <= 1.0, f'Score out of range: {score}'
assert score > 0.3, f'Expected score > 0.3 for strong match, got {score}'

# Test with no skill overlap
low_score = score_lead({'name': 'Biotech Co', 'one_liner': 'DNA sequencing for labs', 'stage': 'Public'}, ['Python'], '')
assert low_score < score, f'Biotech should score lower than DevTools: {low_score} vs {score}'

print(f'scorer OK. DevTools score={score:.3f}, Biotech score={low_score:.3f}')
print(f'YC_OSS_BASE_URL: {YC_OSS_BASE_URL}')
"
    </automated>
  </verify>
  <done>
    `ScoringWeights` instantiates with weights summing to 1.0 (assertion raises otherwise). `score_lead()` returns a float in 0.0-1.0 range. A Python/TypeScript dev-tools company scores higher than an unrelated company. `fetch_yc_companies` and `YC_OSS_BASE_URL` import without error.
  </done>
</task>

<task type="auto">
  <name>Task 2: Scout agent — fetch, filter, dedup, persist leads</name>
  <files>
    src/ingot/agents/scout.py
  </files>
  <action>
Build the Scout agent that orchestrates the full lead discovery pipeline: fetch from yc-oss → score → validate → dedup → persist.

This is NOT a PydanticAI agent (no LLM call needed — data is structured JSON from yc-oss). It is a plain async function with typed dependencies.

**src/ingot/agents/scout.py:**

```python
"""
Scout Agent — YC lead discovery via yc-oss JSON API.

Pipeline:
  1. Fetch YC companies from yc-oss GitHub Pages API (batch or all)
  2. Score each company against UserProfile skills using weighted formula
  3. Validate output: reject company if >20% required fields are None (SCOUT-04)
  4. Deduplicate against existing SQLite Lead records by email (SCOUT-06)
  5. Persist top 10-20 leads sorted by score as status="discovered" (SCOUT-08)

No LLM call — data is structured JSON; LLM is used in Research agent.
"""
import asyncio
from dataclasses import dataclass
from datetime import datetime

import httpx
from sqlalchemy.ext.asyncio import AsyncSession
from sqlmodel import select

from ingot.db.models import Lead, LeadStatus
from ingot.venues.yc import fetch_yc_companies
from ingot.scoring.scorer import ScoringWeights, score_lead, DEFAULT_WEIGHTS


@dataclass
class ScoutDeps:
    http_client: httpx.AsyncClient
    session: AsyncSession
    user_skills: list[str]                       # from UserProfile.skills
    resume_text: str = ""                        # for semantic scoring
    weights: ScoringWeights = DEFAULT_WEIGHTS
    batch: str | None = None                     # YC batch filter, None = recent batches
    max_leads: int = 20                          # CONTEXT.md: 10-20 leads per run
    min_leads: int = 10


_REQUIRED_FIELDS = ["name", "website"]  # fields checked for >20% None validation


def _validate_company_record(company: dict) -> tuple[bool, str]:
    """
    SCOUT-04: Reject if >20% of required fields are None/empty.
    Required fields: name, website.
    Returns (is_valid, reason).
    """
    none_count = sum(1 for f in _REQUIRED_FIELDS if not company.get(f))
    threshold = len(_REQUIRED_FIELDS) * 0.20
    if none_count > threshold:
        return False, f"{none_count}/{len(_REQUIRED_FIELDS)} required fields empty"
    return True, ""


async def _is_duplicate(session: AsyncSession, person_email: str) -> bool:
    """
    SCOUT-06: Case-insensitive email deduplication against existing Lead records.
    Returns True if this email already exists in any status.
    """
    if not person_email or person_email.strip() == "":
        return False  # No email = can't dedup; allow through
    result = await session.exec(
        select(Lead).where(Lead.person_email.ilike(person_email.strip()))
    )
    return result.first() is not None


def _company_to_lead_dict(company: dict, score: float) -> dict:
    """Map a yc-oss company dict to Lead table fields."""
    return {
        "company_name": company.get("name", ""),
        "person_name": "",            # populated in Research Phase 2
        "person_email": "",           # populated in Research Phase 2
        "person_role": "",            # populated in Research Phase 2
        "company_website": company.get("website", ""),
        "source_venue": "yc-oss",
        "status": LeadStatus.discovered,
        "initial_score": round(score, 4),
        "created_at": datetime.utcnow(),
        # Store yc-oss metadata as a note for Research agent
        "_yc_one_liner": company.get("one_liner", ""),
        "_yc_batch": company.get("batch", ""),
        "_yc_stage": company.get("stage", ""),
        "_yc_tags": ",".join(company.get("tags", [])),
        "_yc_is_hiring": company.get("isHiring", False),
    }


async def scout_run(deps: ScoutDeps) -> list[Lead]:
    """
    Run the Scout pipeline. Returns persisted Lead records sorted by score desc.

    SCOUT-01: Discovers leads from venues in parallel (asyncio.gather, YC only in v1)
    SCOUT-02: YC venue as primary discovery source
    SCOUT-05: User-agent set in fetch_yc_companies() via YC_HEADERS
    """
    # Step 1: Fetch — try recent batches first for fresher leads; fall back to all
    batches_to_try = ["winter-2025", "summer-2024"] if not deps.batch else [deps.batch]

    all_companies: list[dict] = []
    for batch in batches_to_try:
        try:
            companies = await fetch_yc_companies(deps.http_client, batch=batch)
            all_companies.extend(companies)
            if len(all_companies) >= 200:
                break
            await asyncio.sleep(0.5)  # SCOUT-05: request delay between fetches
        except Exception:
            continue  # Try next batch

    if not all_companies:
        # Ultimate fallback: all companies
        all_companies = await fetch_yc_companies(deps.http_client, batch=None)

    # Step 2: Score all companies
    scored: list[tuple[float, dict]] = []
    for company in all_companies:
        valid, _ = _validate_company_record(company)
        if not valid:
            continue
        s = score_lead(
            company,
            deps.user_skills,
            resume_text=deps.resume_text,
            weights=deps.weights,
        )
        scored.append((s, company))

    # Step 3: Sort by score descending, take top candidates for dedup check
    scored.sort(key=lambda x: x[0], reverse=True)
    top_candidates = scored[:deps.max_leads * 3]  # Check 3x to account for dedup losses

    # Step 4 + 5: Dedup and persist — update status BEFORE expensive operation (Pitfall 7)
    persisted_leads: list[Lead] = []
    for score, company in top_candidates:
        if len(persisted_leads) >= deps.max_leads:
            break

        company_website = company.get("website", "")
        # person_email is empty at Scout stage; dedup by website as proxy
        is_dup = await _is_duplicate(deps.session, company_website)
        if is_dup:
            continue

        lead_data = _company_to_lead_dict(company, score)
        # Remove internal _yc_* keys before creating Lead (not in schema)
        clean_data = {k: v for k, v in lead_data.items() if not k.startswith("_")}
        lead = Lead(**clean_data)
        deps.session.add(lead)
        await deps.session.commit()
        await deps.session.refresh(lead)
        persisted_leads.append(lead)

    return persisted_leads
```

NOTE: At Scout stage, `person_email` and `person_name` are unknown — they come from Research Phase 2 (contact discovery on the company website). Scout uses `company_website` as a proxy for deduplication at this stage. The `Lead.person_email` dedup (SCOUT-06) is enforced in Research Phase 2 when the email is first populated. This is architecturally correct — Scout discovers companies, Research discovers contacts.
  </action>
  <verify>
    <automated>python -c "
import asyncio, tempfile
from ingot.agents.scout import _validate_company_record, _is_duplicate, _company_to_lead_dict, ScoutDeps
from ingot.db.engine import create_engine, init_db
from ingot.db.models import Lead
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import AsyncSession

async def test():
    # Test _validate_company_record
    valid, _ = _validate_company_record({'name': 'Acme', 'website': 'acme.com'})
    assert valid, 'Valid company should pass'
    invalid, reason = _validate_company_record({'name': '', 'website': ''})
    assert not invalid, f'Empty fields should fail: {reason}'

    # Test dedup via SQLite
    with tempfile.TemporaryDirectory() as d:
        eng = create_engine(f'sqlite+aiosqlite:///{d}/test.db')
        await init_db(eng)
        Session = sessionmaker(eng, class_=AsyncSession, expire_on_commit=False)
        async with Session() as session:
            from datetime import datetime
            from ingot.db.models import LeadStatus
            lead = Lead(company_name='Acme', company_website='acme.com', person_email='jane@acme.com', status=LeadStatus.discovered, created_at=datetime.utcnow())
            session.add(lead)
            await session.commit()
            # Dedup check — same email case-insensitively
            is_dup = await _is_duplicate(session, 'JANE@ACME.COM')
            assert is_dup, 'Should detect case-insensitive duplicate'
            not_dup = await _is_duplicate(session, 'other@acme.com')
            assert not not_dup, 'Different email should not be a duplicate'
        await eng.dispose()

    print('scout.py unit checks OK')

asyncio.run(test())
"
    </automated>
  </verify>
  <done>
    `_validate_company_record()` rejects companies with empty name/website and accepts complete records. `_is_duplicate()` returns `True` for case-insensitively matching emails. `ScoutDeps` and `scout_run` are importable. `_company_to_lead_dict()` maps company fields to Lead schema fields without extra keys.
  </done>
</task>

</tasks>

<verification>
Run after all tasks complete:

```bash
# Full import and logic verification
python -c "
from ingot.venues.yc import fetch_yc_companies, YC_OSS_BASE_URL, YC_HEADERS
from ingot.scoring.scorer import ScoringWeights, score_lead, DEFAULT_WEIGHTS, _stack_domain_score, _stage_score
from ingot.agents.scout import scout_run, ScoutDeps, _validate_company_record

# Verify weights sum
assert abs(sum([DEFAULT_WEIGHTS.stack_domain_match, DEFAULT_WEIGHTS.company_stage,
               DEFAULT_WEIGHTS.job_keyword_match, DEFAULT_WEIGHTS.semantic_similarity]) - 1.0) < 0.001

# Verify User-Agent is set
assert 'INGOT' in YC_HEADERS.get('User-Agent', ''), 'Missing INGOT User-Agent'

# Verify URL is yc-oss NOT ycombinator.com
assert 'yc-oss.github.io' in YC_OSS_BASE_URL, f'Wrong URL: {YC_OSS_BASE_URL}'

# Verify stage scoring
seed_score = _stage_score({'stage': 'Seed'})
public_score = _stage_score({'stage': 'Public'})
assert seed_score > public_score, 'Seed should score higher than Public'

print('All Scout verifications OK')
print(f'  YC URL: {YC_OSS_BASE_URL}')
print(f'  Weights: {DEFAULT_WEIGHTS}')
print(f'  Seed score: {seed_score}, Public score: {public_score}')
"
```
</verification>

<success_criteria>
- `fetch_yc_companies()` targets `yc-oss.github.io/api/` (NOT `ycombinator.com`)
- `ScoringWeights` sums to 1.0; documented in code docstring with rationale
- `score_lead()` produces 0.0-1.0; stack_domain_match reads `one_liner` + `long_description` text (NOT tags)
- `_is_duplicate()` handles case-insensitive email comparison correctly
- `scout_run()` is importable and wires fetch → score → validate → dedup → persist
- `User-Agent: INGOT/0.1` set on all httpx requests (SCOUT-05)
- Output validation rejects companies with >20% required fields None (SCOUT-04)
- SCOUT-01 through SCOUT-08 requirements all addressed
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-pipeline-scout-through-writer/02-02-SUMMARY.md` with:
- Confirmed YC-OSS API URL and response field coverage
- Final ScoringWeights values (may have been tuned during implementation)
- Dedup strategy note: Scout uses company_website as proxy; Research Phase 2 enforces person_email dedup
- Any issues encountered with yc-oss API (coverage gaps, missing stage field, etc.)
</output>
